{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5cJ3XAu86oT"
      },
      "source": [
        "## Extract keywords from story"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSlyy1u_9vA-"
      },
      "source": [
        "# Installing from https://github.com/boudinfl/pke library for Python Keyword extraction\n",
        "# We use a fixed commit as the later changes might break the code. If it was on pip we would have used exact version number.\n",
        "\n",
        "# !pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
        "# !pip install --quiet flashtext==2.7\n",
        "\n",
        "\n",
        "!pip install --quiet flashtext==2.7\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install transformers==4.28.1\n",
        "# !pip install tokenizers==0.9.4\n",
        "!pip install sentencepiece==0.1.97\n",
        "# !pip install --no-dependencies transformers==2.9.0\n",
        "\n",
        "# !pip install transformers==3.4.0\n",
        "# !pip install transformers==4.1.0\n",
        "# tokenizers-0.9.4\n",
        "\n",
        "# !pip install --quiet nltk==3.4.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR6rMLaaM37X",
        "outputId": "75886968-2164-43d5-baf2-4323d5abf53c"
      },
      "source": [
        "# connect your personal google drive to store the trained model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bTE46mP-nYj",
        "outputId": "b0c2b26f-b076-424b-e813-73db5beccc54"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import itertools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import pke\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "import traceback\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvZ2DG299ApF",
        "outputId": "8e6c2e64-1a2c-4089-ebdb-1e0ee7a9d63b"
      },
      "source": [
        "import textwrap\n",
        "# Story source - https://byjus.com/kids-learning/moral-stories-the-lion-and-the-mouse/\n",
        "\n",
        "text = \"\"\" Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
        "\n",
        "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.\n",
        "\n",
        "A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
        "\n",
        "As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
        "\n",
        "The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good friends and lived happily in the forest. \"\"\"\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=150)\n",
        "word_list = wrapper.wrap(text=text)\n",
        "for element in word_list:\n",
        "  print(element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse\n",
            "unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how\n",
            "could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.  A few days later, a hunter set\n",
            "a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to\n",
            "free himself and roared loudly in anger.  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the\n",
            "hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore\n",
            "apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.  The lion thanked the little mouse for\n",
            "her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good\n",
            "friends and lived happily in the forest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSDB9XDd9YBu",
        "outputId": "2da5f457-2393-4b29-e6cd-d2314dfcf9d5"
      },
      "source": [
        "def get_keywords(text):\n",
        "    out=[]\n",
        "    try:\n",
        "        # extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor = pke.unsupervised.YAKE()\n",
        "        extractor.load_document(input=text,language='en')\n",
        "        grammar = r\"\"\"\n",
        "                NP:\n",
        "                    {<NOUN|PROPN>+}\n",
        "            \"\"\"\n",
        "        extractor.ngram_selection(n=1)\n",
        "        extractor.grammar_selection(grammar=grammar)\n",
        "        # pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "        # pos ={'NOUN'}\n",
        "        # stoplist = list(string.punctuation)\n",
        "        # stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        # stoplist += stopwords.words('english')\n",
        "        # extractor.candidate_selection(n=1,pos=pos, stoplist=stoplist)\n",
        "        extractor.candidate_selection(n=1)\n",
        "\n",
        "        extractor.candidate_weighting(window=3,\n",
        "                                      use_stems=False)\n",
        "\n",
        "        keyphrases = extractor.get_n_best(n=30)\n",
        "\n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_keywords(text)[:8]\n",
        "print (\"keywords: \",keywords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keywords:  ['lion', 'mouse', 'amazon', 'net', 'hunter', 'tiny', 'free', 'big']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO3owrXlWObz",
        "outputId": "65a98b50-4cd8-412c-e7a3-ba08ee195fe6"
      },
      "source": [
        "sentences = tokenize_sentences(text)\n",
        "print (sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once upon a time, there lived a lion in the dense Amazon rainforest.', 'While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.', 'This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.', 'The poor mouse begged the lion to spare her this time and she would pay him back on some other day.', 'Hearing this, the lion was amused and wondered how could such a tiny creature ever help him.', 'But he was in a good mood and in his generosity he finally let the mouse go.', 'A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest.', 'Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.', 'As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net.', 'The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart.', 'Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.', 'The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before.', 'Thereafter, the lion and the mouse became good friends and lived happily in the forest.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvjVX2dYWWNB",
        "outputId": "56c9b8bc-3fc7-40ad-8ef2-4b3d3f42e9ed"
      },
      "source": [
        "from pprint import pprint\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=False)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "pprint (keyword_sentence_mapping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'amazon': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "            'rainforest.'],\n",
            " 'big': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'A few days later, a hunter set a trap for the lion while the big '\n",
            "         'animal was stalking for prey in the forest.',\n",
            "         'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "         'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "         'in haste.'],\n",
            " 'free': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.'],\n",
            " 'hunter': ['Slowly she made a big hole in the net and soon the lion was able '\n",
            "            'to free himself from the hunter’s trap.',\n",
            "            'A few days later, a hunter set a trap for the lion while the big '\n",
            "            'animal was stalking for prey in the forest.',\n",
            "            'Caught in the toils of a hunter’s net, the lion found it '\n",
            "            'difficult to free himself and roared loudly in anger.',\n",
            "            'As the mouse was passing by, she heard the roar and found the '\n",
            "            'lion struggling hard to free himself from the hunter’s net.'],\n",
            " 'lion': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "          'rainforest.',\n",
            "          'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Thereafter, the lion and the mouse became good friends and lived '\n",
            "          'happily in the forest.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'The poor mouse begged the lion to spare her this time and she would '\n",
            "          'pay him back on some other day.',\n",
            "          'Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'A few days later, a hunter set a trap for the lion while the big '\n",
            "          'animal was stalking for prey in the forest.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The little creature quickly ran towards the lion’s trap that bound '\n",
            "          'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "          'apart.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.'],\n",
            " 'mouse': ['But he was in a good mood and in his generosity he finally let the '\n",
            "           'mouse go.',\n",
            "           'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "           'mouse to kill her.',\n",
            "           'Thereafter, the lion and the mouse became good friends and lived '\n",
            "           'happily in the forest.',\n",
            "           'The poor mouse begged the lion to spare her this time and she '\n",
            "           'would pay him back on some other day.',\n",
            "           'As the mouse was passing by, she heard the roar and found the lion '\n",
            "           'struggling hard to free himself from the hunter’s net.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "           'little mouse unexpectedly crossed by and ran across the lion’s '\n",
            "           'nose in haste.'],\n",
            " 'net': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "         'to free himself and roared loudly in anger.',\n",
            "         'As the mouse was passing by, she heard the roar and found the lion '\n",
            "         'struggling hard to free himself from the hunter’s net.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.'],\n",
            " 'tiny': ['This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neRbWQhO4GnG"
      },
      "source": [
        "## Download pretrained BERT WSD Model - Run only once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNz0zFZzrXqN"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "bert_wsd_pytorch = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "extract_directory = \"/content/gdrive/My Drive\"\n",
        "\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
        "\n",
        "#  If unzipped folder exists don't unzip again.\n",
        "if not os.path.isdir(extracted_folder):\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_directory)\n",
        "else:\n",
        "  print (extracted_folder,\" is extracted already\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GtYSH2ewtO4"
      },
      "source": [
        "# Run model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses==0.0.53"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nPXW7R_4kqg",
        "outputId": "5e560e94-eb03-4326-8402-9ce53a1755ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses==0.0.53\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/880.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=3ce39c85157b2b422b760c468fac43d7c57c768d0febae59858fee1418c24858\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmszaP9zSpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed760ad-63fd-45a0-aa63-e858c25802bb"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "class BertWSD(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dir = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
        "\n",
        "\n",
        "model = BertWSD.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "tokenizer.added_tokens_encoder['[TGT]'] = 100\n",
        "# add new special token\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6 were not used when initializing BertWSD: ['similarity_linear.bias', 'similarity_linear.weight', 'ranking_loss_factor', 'similarity_loss_factor']\n",
            "- This IS expected if you are initializing BertWSD from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertWSD from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWSD(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bWxo4vFUfH",
        "outputId": "fd8b56fc-1102-4262-962c-1c37cbd1cfd0"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
        "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
        "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
        "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
        "        context-example pairs (if available)\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\n",
        "\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
        "\n",
        "        pairs = []\n",
        "        for seq, label in sequences:\n",
        "            tokens_b = tokenizer.tokenize(seq)\n",
        "\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "\n",
        "            # The convention in BERT is:\n",
        "            # (a) For sequence pairs:\n",
        "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "            #\n",
        "            # Where \"type_ids\" are used to indicate whether this is the first\n",
        "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "            # embedding vector (and position vector). This is not *strictly* necessary\n",
        "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "            # it easier for the model to learn the concept of sequences.\n",
        "            #\n",
        "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "            # the entire model is fine-tuned.\n",
        "            tokens = tokens_a + [sep_token]\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "            if cls_token_at_end:\n",
        "                tokens = tokens + [cls_token]\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\n",
        "            else:\n",
        "                tokens = [cls_token] + tokens\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "            # tokens are attended to.\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "            # Zero-pad up to the sequence length.\n",
        "            padding_length = max_seq_length - len(input_ids)\n",
        "            if pad_on_left:\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            else:\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "\n",
        "            pairs.append(\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
        "            )\n",
        "\n",
        "        features.append(pairs)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbPKBjr-KTp",
        "outputId": "1826284d-dfd1-4aa2-add6-2e63300f7ad7"
      },
      "source": [
        "from pprint import pprint\n",
        "nltk.download('omw-1.4')\n",
        "sentence = \"Mark's favourite game is **Cricket**.\"\n",
        "\n",
        "sentence_for_bert = sentence.replace(\"**\",\" [TGT] \")\n",
        "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        "\n",
        "print (sentence_for_bert)\n",
        "\n",
        "re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sentence_for_bert)\n",
        "if re_result is None:\n",
        "    print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "ambiguous_word = re_result.group(1).strip()\n",
        "\n",
        "print (\"Word: \",ambiguous_word)\n",
        "\n",
        "\n",
        "results = dict()\n",
        "\n",
        "# wn_pos = wn.NOUN\n",
        "# for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n",
        "for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "    results[synset] =  synset.definition()\n",
        "\n",
        "pprint (results)\n",
        "\n",
        "sense_keys=[]\n",
        "definitions=[]\n",
        "for sense_key, definition in results.items():\n",
        "    sense_keys.append(sense_key)\n",
        "    definitions.append(definition)\n",
        "\n",
        "\n",
        "print (sense_keys)\n",
        "print (definitions)\n",
        "\n",
        "\n",
        "record = GlossSelectionRecord(\"test\", sentence_for_bert, sense_keys, definitions, [-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mark's favourite game is [TGT] Cricket [TGT] .\n",
            "Word:  Cricket\n",
            "{Synset('cricket.n.01'): 'leaping insect; male makes chirping noises by '\n",
            "                         'rubbing the forewings together',\n",
            " Synset('cricket.n.02'): 'a game played with a ball and bat by two teams of 11 '\n",
            "                         'players; teams take turns trying to score runs',\n",
            " Synset('cricket.v.01'): 'play cricket'}\n",
            "[Synset('cricket.v.01'), Synset('cricket.n.02'), Synset('cricket.n.01')]\n",
            "['play cricket', 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', 'leaping insect; male makes chirping noises by rubbing the forewings together']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtZDDEUCrVRl",
        "outputId": "ff68ecbc-aeed-46ef-f687-9164e11380ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30523"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix16JsX7fyt1",
        "outputId": "3e7a8ce3-ec9d-4fea-c510-d3e99f6a5bf1"
      },
      "source": [
        "features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                          cls_token=tokenizer.cls_token,\n",
        "                                          sep_token=tokenizer.sep_token,\n",
        "                                          cls_token_segment_id=1,\n",
        "                                          pad_token_segment_id=0,\n",
        "                                          disable_progress_bar=True)[0]\n",
        "\n",
        "print (len(features))\n",
        "\n",
        "for ftr in features:\n",
        "  print (tokenizer.convert_ids_to_tokens(ftr.input_ids))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'play', 'cricket', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'a', 'game', 'played', 'with', 'a', 'ball', 'and', 'bat', 'by', 'two', 'teams', 'of', '11', 'players', ';', 'teams', 'take', 'turns', 'trying', 'to', 'score', 'runs', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'leaping', 'insect', ';', 'male', 'makes', 'chi', '##rp', '##ing', 'noises', 'by', 'rubbing', 'the', 'forewings', 'together', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aucvx7VAEhj-",
        "outputId": "c164c5db-3a7b-497d-84be-391a884eb9e5"
      },
      "source": [
        "with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "print (\"\\n\")\n",
        "for pred in preds:\n",
        "  print (pred)\n",
        "sense = preds[0][0]\n",
        "meaning = preds[0][1]\n",
        "\n",
        "print (\"\\nMost appropriate sense: \",sense)\n",
        "print (\"Most appropriate meaning: \",meaning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "(Synset('cricket.n.02'), 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', tensor(0.6093, dtype=torch.float64))\n",
            "(Synset('cricket.v.01'), 'play cricket', tensor(0.3907, dtype=torch.float64))\n",
            "(Synset('cricket.n.01'), 'leaping insect; male makes chirping noises by rubbing the forewings together', tensor(9.1672e-06, dtype=torch.float64))\n",
            "\n",
            "Most appropriate sense:  Synset('cricket.n.02')\n",
            "Most appropriate meaning:  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJSpZRuOF-52"
      },
      "source": [
        "def get_sense(sent):\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
        "  if re_result is None:\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "  ambiguous_word = re_result.group(1).strip()\n",
        "  results = dict()\n",
        "\n",
        "  for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "      results[synset] =  synset.definition()\n",
        "\n",
        "  if len(results) ==0:\n",
        "    return None\n",
        "\n",
        "  sense_keys=[]\n",
        "  definitions=[]\n",
        "  for sense_key, definition in results.items():\n",
        "      sense_keys.append(sense_key)\n",
        "      definitions.append(definition)\n",
        "\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
        "\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            cls_token_segment_id=1,\n",
        "                                            pad_token_segment_id=0,\n",
        "                                            disable_progress_bar=True)[0]\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "  sense = preds[0][0]\n",
        "  meaning = preds[0][1]\n",
        "  return sense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2aOpD1WASMl",
        "outputId": "eed173eb-0ed3-405a-aaf6-bbaad7750b02"
      },
      "source": [
        "import statistics\n",
        "from statistics import mode\n",
        "import re\n",
        "\n",
        "def get_synsets_for_word (word):\n",
        "  return set(wn.synsets(word))\n",
        "\n",
        "keyword_best_sense = {}\n",
        "\n",
        "for keyword in  keyword_sentence_mapping:\n",
        "  print (\"\\n\\n\")\n",
        "  print(\"Original word: \",keyword)\n",
        "  try:\n",
        "    identified_synsets=get_synsets_for_word(keyword)\n",
        "  except:\n",
        "    continue\n",
        "  for synset in identified_synsets:\n",
        "    print (synset,\"   \",synset.definition())\n",
        "  top_3_sentences = keyword_sentence_mapping[keyword][:3]\n",
        "  best_senses=[]\n",
        "  for sent in top_3_sentences:\n",
        "    insensitive_keyword = re.compile(re.escape(keyword), re.IGNORECASE)\n",
        "    modified_sentence = insensitive_keyword.sub(\" [TGT] \"+keyword+\" [TGT] \", sent,count=1)\n",
        "    modified_sentence = \" \".join(modified_sentence.split())\n",
        "    print (\"modified sentence \",modified_sentence)\n",
        "    best_sense = get_sense(modified_sentence)\n",
        "    best_senses.append(best_sense)\n",
        "  best_sense = mode(best_senses)\n",
        "  print (\"Best sense: \",best_sense)\n",
        "  defn = best_sense.definition()\n",
        "  print (defn)\n",
        "  keyword_best_sense [keyword] = defn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Original word:  lion\n",
            "Synset('leo.n.01')     (astrology) a person who is born while the sun is in Leo\n",
            "Synset('leo.n.03')     the fifth sign of the zodiac; the sun is in this sign from about July 23 to August 22\n",
            "Synset('lion.n.02')     a celebrity who is lionized (much sought after)\n",
            "Synset('lion.n.01')     large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "modified sentence  Once upon a time, there lived a [TGT] lion [TGT] in the dense Amazon rainforest.\n",
            "modified sentence  This woke up the [TGT] lion [TGT] and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "modified sentence  Thereafter, the [TGT] lion [TGT] and the mouse became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('lion.n.01')\n",
            "large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "\n",
            "\n",
            "\n",
            "Original word:  mouse\n",
            "Synset('sneak.v.01')     to go stealthily or furtively\n",
            "Synset('mouse.n.01')     any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "Synset('mouse.v.02')     manipulate the mouse of a computer\n",
            "Synset('shiner.n.01')     a swollen bruise caused by a blow to the eye\n",
            "Synset('mouse.n.03')     person who is quiet or timid\n",
            "Synset('mouse.n.04')     a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; on the bottom of the device is a ball that rolls on the surface of the pad\n",
            "modified sentence  But he was in a good mood and in his generosity he finally let the [TGT] mouse [TGT] go.\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the tiny [TGT] mouse [TGT] to kill her.\n",
            "modified sentence  Thereafter, the lion and the [TGT] mouse [TGT] became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('mouse.n.01')\n",
            "any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "\n",
            "\n",
            "\n",
            "Original word:  amazon\n",
            "Synset('amazon.n.02')     (Greek mythology) one of a nation of women warriors of Scythia (who burned off the right breast in order to use a bow and arrow more effectively)\n",
            "Synset('amazon.n.01')     a large strong and aggressive woman\n",
            "Synset('amazon.n.04')     mainly green tropical American parrots\n",
            "Synset('amazon.n.03')     a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "modified sentence  Once upon a time, there lived a lion in the dense [TGT] amazon [TGT] rainforest.\n",
            "Best sense:  Synset('amazon.n.03')\n",
            "a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "\n",
            "\n",
            "\n",
            "Original word:  net\n",
            "Synset('net.n.06')     an open fabric of string or rope or wire woven together at regular intervals\n",
            "Synset('net.n.04')     a goal lined with netting (as in soccer or hockey)\n",
            "Synset('final.s.02')     conclusive in a process or progression\n",
            "Synset('net.v.02')     yield as a net profit\n",
            "Synset('net.n.02')     a trap made of netting to catch fish or birds or insects\n",
            "Synset('net.v.01')     make as a net profit\n",
            "Synset('net.v.04')     catch with a net\n",
            "Synset('net_income.n.01')     the excess of revenues over outlays in a given period of time (including depreciation and other non-cash expenses)\n",
            "Synset('net.a.01')     remaining after all deductions\n",
            "Synset('internet.n.01')     a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange\n",
            "Synset('web.v.01')     construct or form a web, as if by weaving\n",
            "Synset('net.n.05')     game equipment consisting of a strip of netting dividing the playing area in tennis or badminton\n",
            "modified sentence  Slowly she made a big hole in the [TGT] net [TGT] and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s [TGT] net [TGT] , the lion found it difficult to free himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s [TGT] net [TGT] .\n",
            "Best sense:  Synset('net.n.02')\n",
            "a trap made of netting to catch fish or birds or insects\n",
            "\n",
            "\n",
            "\n",
            "Original word:  hunter\n",
            "Synset('hunter.n.02')     a person who searches for something\n",
            "Synset('hunter.n.04')     a watch with a hinged metal lid to protect the crystal\n",
            "Synset('orion.n.02')     a constellation on the equator to the east of Taurus; contains Betelgeuse and Rigel\n",
            "Synset('hunter.n.01')     someone who hunts game\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to free himself from the [TGT] hunter [TGT] ’s trap.\n",
            "modified sentence  A few days later, a [TGT] hunter [TGT] set a trap for the lion while the big animal was stalking for prey in the forest.\n",
            "modified sentence  Caught in the toils of a [TGT] hunter [TGT] ’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
            "Best sense:  Synset('hunter.n.01')\n",
            "someone who hunts game\n",
            "\n",
            "\n",
            "\n",
            "Original word:  tiny\n",
            "Synset('bantam.s.01')     very small\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the [TGT] tiny [TGT] mouse to kill her.\n",
            "modified sentence  Hearing this, the lion was amused and wondered how could such a [TGT] tiny [TGT] creature ever help him.\n",
            "modified sentence  While he was sleeping by resting his big head on his paws, a [TGT] tiny [TGT] little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('bantam.s.01')\n",
            "very small\n",
            "\n",
            "\n",
            "\n",
            "Original word:  free\n",
            "Synset('free.a.01')     able to act at will; not hampered; not under compulsion or restraint\n",
            "Synset('rid.v.01')     relieve from\n",
            "Synset('free.v.01')     grant freedom to; free from confinement\n",
            "Synset('free.v.05')     make (information) available for publication\n",
            "Synset('spare.s.03')     not taken up by scheduled activities\n",
            "Synset('unblock.v.03')     make (assets) available\n",
            "Synset('free.v.06')     free from obligations or duties\n",
            "Synset('free.v.07')     free or remove obstruction from\n",
            "Synset('free.a.02')     unconstrained or not chemically bound in a molecule or not fixed and capable of relatively unrestricted motion\n",
            "Synset('barren.s.03')     completely wanting or lacking\n",
            "Synset('complimentary.s.02')     costing nothing\n",
            "Synset('free.n.01')     people who are free\n",
            "Synset('loose.r.01')     without restraint\n",
            "Synset('release.v.09')     release (gas or energy) as a result of a chemical reaction or physical decomposition\n",
            "Synset('dislodge.v.01')     remove or force out from a position\n",
            "Synset('detached.s.06')     not fixed in position\n",
            "Synset('free.a.06')     not held in servitude\n",
            "Synset('free.s.09')     not literal\n",
            "Synset('absolve.v.02')     let off the hook\n",
            "Synset('release.v.08')     part with a possession or right\n",
            "Synset('exempt.v.01')     grant relief or an exemption from a rule or requirement to\n",
            "Synset('free.s.04')     not occupied or in use\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to [TGT] free [TGT] himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s net, the lion found it difficult to [TGT] free [TGT] himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to [TGT] free [TGT] himself from the hunter’s net.\n",
            "Best sense:  Synset('free.a.01')\n",
            "able to act at will; not hampered; not under compulsion or restraint\n",
            "\n",
            "\n",
            "\n",
            "Original word:  big\n",
            "Synset('big.s.11')     generous and understanding and tolerant\n",
            "Synset('big.s.04')     loud and firm\n",
            "Synset('adult.s.01')     (of animals) fully developed\n",
            "Synset('large.a.01')     above average in size or number or quantity or magnitude or extent\n",
            "Synset('big.s.02')     significant\n",
            "Synset('boastful.s.01')     exhibiting self-importance\n",
            "Synset('big.s.12')     given or giving freely\n",
            "Synset('big.s.06')     prodigious\n",
            "Synset('boastfully.r.01')     in a boastful manner\n",
            "Synset('big.s.10')     marked by intense physical force\n",
            "Synset('big.s.13')     in an advanced stage of pregnancy\n",
            "Synset('big.s.08')     feeling self-importance\n",
            "Synset('big.r.03')     on a grand scale\n",
            "Synset('bad.s.02')     very intense\n",
            "Synset('big.r.01')     extremely well\n",
            "Synset('big.r.04')     in a major way\n",
            "Synset('big.s.05')     conspicuous in position or importance\n",
            "modified sentence  Slowly she made a [TGT] big [TGT] hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  A few days later, a hunter set a trap for the lion while the [TGT] big [TGT] animal was stalking for prey in the forest.\n",
            "modified sentence  While he was sleeping by resting his [TGT] big [TGT] head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('large.a.01')\n",
            "above average in size or number or quantity or magnitude or extent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypSVwXu7eoA3",
        "outputId": "30656562-1420-4ee6-bd35-790c1bb1bb92"
      },
      "source": [
        "pprint (keyword_best_sense)\n",
        "\n",
        "# {'amazon': 'a major South American river; arises in the Andes and flows '\n",
        "#            \"eastward into the South Atlantic; the world's 2nd longest river \"\n",
        "#            '(4000 miles)',\n",
        "#  'big': 'above average in size or number or quantity or magnitude or extent',\n",
        "#  'free': 'able to act at will; not hampered; not under compulsion or restraint',\n",
        "#  'hunter': 'someone who hunts game',\n",
        "#  'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n",
        "#          'coat with a shaggy mane in the male',\n",
        "#  'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n",
        "#           'having pointed snouts and small ears on elongated bodies with '\n",
        "#           'slender usually hairless tails',\n",
        "#  'net': 'a trap made of netting to catch fish or birds or insects',\n",
        "#  'tiny': 'very small'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'amazon': 'a major South American river; arises in the Andes and flows '\n",
            "           \"eastward into the South Atlantic; the world's 2nd longest river \"\n",
            "           '(4000 miles)',\n",
            " 'big': 'above average in size or number or quantity or magnitude or extent',\n",
            " 'free': 'able to act at will; not hampered; not under compulsion or restraint',\n",
            " 'hunter': 'someone who hunts game',\n",
            " 'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n",
            "         'coat with a shaggy mane in the male',\n",
            " 'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n",
            "          'having pointed snouts and small ears on elongated bodies with '\n",
            "          'slender usually hairless tails',\n",
            " 'net': 'a trap made of netting to catch fish or birds or insects',\n",
            " 'tiny': 'very small'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ZAzdJZZH7h",
        "outputId": "9e980e16-5673-465e-c6bd-798efb01c977"
      },
      "source": [
        "import random\n",
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "all_keywords= list(keyword_best_sense.keys())\n",
        "all_definitions = list(keyword_best_sense.values())\n",
        "random.shuffle(all_keywords)\n",
        "random.shuffle(all_definitions)\n",
        "print (all_keywords)\n",
        "print (all_definitions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hunter', 'net', 'amazon', 'tiny', 'mouse', 'free', 'lion', 'big']\n",
            "['someone who hunts game', 'above average in size or number or quantity or magnitude or extent', 'very small', 'any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails', 'able to act at will; not hampered; not under compulsion or restraint', \"a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\", 'a trap made of netting to catch fish or birds or insects', 'large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "sVIdVRmDjcxn",
        "outputId": "b3fe5a58-f59d-4330-c274-cd408a346c3b"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "x.field_names=['Word', \"Definition\"]\n",
        "for word,defn in zip(all_keywords,all_definitions):\n",
        "  x.add_row([word,defn])\n",
        "\n",
        "printmd(\"**Match the following words to their correct meanings.**\")\n",
        "# print (\"\\n\")\n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Match the following words to their correct meanings.**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  Word  |                                                                            Definition                                                                           |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| hunter |                                                                      someone who hunts game                                                                     |\n",
            "|  net   |                                                above average in size or number or quantity or magnitude or extent                                               |\n",
            "| amazon |                                                                            very small                                                                           |\n",
            "|  tiny  | any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails |\n",
            "| mouse  |                                               able to act at will; not hampered; not under compulsion or restraint                                              |\n",
            "|  free  |             a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)            |\n",
            "|  lion  |                                                     a trap made of netting to catch fish or birds or insects                                                    |\n",
            "|  big   |                             large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male                            |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}